{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Ruta absoluta del directorio de datos del usuario\n",
    "user_data_dir = os.path.abspath(\"chrome_user_data\")\n",
    "\n",
    "# Crear el directorio si no existe\n",
    "if not os.path.exists(user_data_dir):\n",
    "    os.makedirs(user_data_dir)\n",
    "\n",
    "# Configurar opciones de Chrome\n",
    "chrome_options = Options()\n",
    "# chrome_options.add_argument(\"--headless\")  # Ejecutar en modo headless\n",
    "chrome_options.add_argument(\"--start-maximized\")  # Abrir el navegador en pantalla completa\n",
    "# Establecer el perfil de usuario\n",
    "chrome_options.add_argument(f\"user-data-dir={user_data_dir}\")\n",
    "\n",
    "# Descargar y configurar el controlador de Chrome automáticamente\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# Abrir el navegador y navegar a Apollo.io\n",
    "driver.get(\"https://app.apollo.io/#/login\")\n",
    "\n",
    "# Esperar unos segundos para ver el navegador abierto antes de empezar a interactuar\n",
    "time.sleep(5)\n",
    "\n",
    "# Intentar encontrar el campo de correo electrónico por su XPath y rellenarlo\n",
    "email_xpath = '/html/body/div[2]/div/div[2]/div/div[1]/div/div[2]/div/div[2]/div/form/div[2]/div/div/input'\n",
    "try:\n",
    "    email_input = WebDriverWait(driver, 10).until(\n",
    "        EC.visibility_of_element_located((By.XPATH, email_xpath))\n",
    "    )\n",
    "    email_input.send_keys(\"Gbustosgarcia01@gmail.com\")\n",
    "    print(\"El campo de correo electrónico fue rellenado.\")\n",
    "except Exception as e:\n",
    "    print(f\"El campo de correo electrónico no fue encontrado: {e}\")\n",
    "\n",
    "# Intentar encontrar el campo de contraseña por su XPath y rellenarlo\n",
    "password_xpath = '/html/body/div[2]/div/div[2]/div/div[1]/div/div[2]/div/div[2]/div/form/div[3]/div/div[1]/div/input'\n",
    "try:\n",
    "    password_input = WebDriverWait(driver, 10).until(\n",
    "        EC.visibility_of_element_located((By.XPATH, password_xpath))\n",
    "    )\n",
    "    password_input.send_keys(\"LG030920..lg.\")\n",
    "    print(\"El campo de contraseña fue rellenado.\")\n",
    "except Exception as e:\n",
    "    print(f\"El campo de contraseña no fue encontrado: {e}\")\n",
    "\n",
    "# Intentar encontrar el botón de Log In por su XPath y hacer clic en él\n",
    "login_button_xpath = '/html/body/div[2]/div/div[2]/div/div[1]/div/div[2]/div/div[2]/div/form/div[4]/button'\n",
    "try:\n",
    "    login_button = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, login_button_xpath))\n",
    "    )\n",
    "    login_button.click()\n",
    "    print(\"El botón de Log In fue clickeado.\")\n",
    "except Exception as e:\n",
    "    print(f\"El botón de Log In no fue encontrado o no fue clickeable: {e}\")\n",
    "\n",
    "# Esperar unos segundos para asegurar que el inicio de sesión se complete\n",
    "time.sleep(10)\n",
    "\n",
    "# Cerrar el navegador\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import csv\n",
    "import time\n",
    "\n",
    "# Configurar opciones de Chrome\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Ejecutar en modo headless\n",
    "chrome_options.add_argument(\"--start-maximized\")  # Abrir el navegador en pantalla completa\n",
    "user_data_dir = \"chrome_user_data\"\n",
    "chrome_options.add_argument(f\"user-data-dir={user_data_dir}\")\n",
    "\n",
    "# Descargar y configurar el controlador de Chrome automáticamente\n",
    "def start_driver():\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    return webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "driver = start_driver()\n",
    "\n",
    "csv_file_path = 'Resultados/Empresas/Apollo_Acounts_1-10.csv'\n",
    "rows = []\n",
    "company_urls = {}  # Diccionario para mapear URLs a sus índices de fila\n",
    "\n",
    "# Verificar y añadir columnas si no existen\n",
    "with open(csv_file_path, mode='r', newline='', encoding='utf-8') as file:\n",
    "    csv_reader = csv.DictReader(file)\n",
    "    existing_fieldnames = csv_reader.fieldnames\n",
    "    required_columns = ['Website', 'LinkeIn', 'Faceboock', 'Twitter', 'Descripción', 'Processed']\n",
    "    \n",
    "    if not all(column in existing_fieldnames for column in required_columns):\n",
    "        fieldnames = existing_fieldnames + [column for column in required_columns if column not in existing_fieldnames]\n",
    "    else:\n",
    "        fieldnames = existing_fieldnames\n",
    "\n",
    "    for index, row in enumerate(csv_reader):\n",
    "        rows.append(row)\n",
    "        company_urls[row.get('Company URL')] = index  # Guardar el índice de fila por URL\n",
    "\n",
    "num_rows_to_process = 10000  # Cambia este valor según sea necesario\n",
    "processed_rows = 0\n",
    "\n",
    "def write_to_csv(rows, fieldnames):\n",
    "    with open(csv_file_path, mode='w', newline='', encoding='utf-8') as updated_file:\n",
    "        csv_writer = csv.DictWriter(updated_file, fieldnames=fieldnames)\n",
    "        csv_writer.writeheader()\n",
    "        csv_writer.writerows(rows)\n",
    "\n",
    "for row_index, row in enumerate(rows):\n",
    "    if processed_rows >= num_rows_to_process:\n",
    "        break\n",
    "\n",
    "    if row.get('Processed') == 'yes':\n",
    "        print(f\"Fila {row_index + 1} ya está completa. Pasando a la siguiente fila.\")\n",
    "        continue\n",
    "\n",
    "    if any([not row.get(col, '').strip() for col in required_columns if col != 'Processed']):\n",
    "        company_name = row.get('Company', '')\n",
    "        company_url = row.get('Company URL', '')\n",
    "\n",
    "        print(f\"Procesando fila {row_index + 1} - Empresa: {company_name}\")\n",
    "\n",
    "        try:\n",
    "            driver.get(company_url)\n",
    "            time.sleep(2)\n",
    "\n",
    "            div_xpath = '/html/body/div[2]/div/div[2]/div[2]/div/div[2]/div/div/div[2]/div[2]/div/div/div/div[1]/div[1]/div[1]/div/div/div/div/div[1]/div[2]'\n",
    "            links = {\n",
    "                'Website': row.get('Website', 'No tiene Website'),\n",
    "                'LinkeIn': row.get('LinkeIn', 'No tiene LinkeIn'),\n",
    "                'Faceboock': row.get('Faceboock', 'No tiene Faceboock'),\n",
    "                'Twitter': row.get('Twitter', 'No tiene Twitter'),\n",
    "                'Descripción': row.get('Descripción', 'No tiene descripción'),\n",
    "            }\n",
    "\n",
    "            if any([not row.get(col, '').strip() for col in required_columns if col != 'Processed']):\n",
    "                try:\n",
    "                    div_element = WebDriverWait(driver, 10).until(\n",
    "                        EC.presence_of_element_located((By.XPATH, div_xpath))\n",
    "                    )\n",
    "                    link_elements = div_element.find_elements(By.TAG_NAME, 'a')\n",
    "                    \n",
    "                    for link in link_elements:\n",
    "                        href = link.get_attribute('href')\n",
    "                        if href:\n",
    "                            if 'linkedin.com' in href:\n",
    "                                links['LinkeIn'] = href\n",
    "                            elif 'facebook.com' in href:\n",
    "                                links['Faceboock'] = href\n",
    "                            elif 'twitter.com' in href or 'x.com' in href:\n",
    "                                links['Twitter'] = href\n",
    "                            else:\n",
    "                                if links['Website'] == 'No tiene Website':\n",
    "                                    links['Website'] = href\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"No se pudo encontrar el div con enlaces: {e}\")\n",
    "\n",
    "                show_more_xpath = '/html/body/div[2]/div/div[2]/div[2]/div/div[2]/div/div/div[2]/div[2]/div/div/div/div[1]/div[1]/div[2]/div/div/div/div/div/div[1]/div/div/div/span/a'\n",
    "                try:\n",
    "                    show_more_button = WebDriverWait(driver, 10).until(\n",
    "                        EC.element_to_be_clickable((By.XPATH, show_more_xpath))\n",
    "                    )\n",
    "                    show_more_button.click()\n",
    "                    \n",
    "                    time.sleep(2)\n",
    "                    \n",
    "                    description_xpath = '/html/body/div[2]/div/div[2]/div[2]/div/div[2]/div/div/div[2]/div[2]/div/div/div/div[1]/div[1]/div[2]/div/div/div/div/div/div[1]/div/div/div/span/span'\n",
    "                    try:\n",
    "                        description_element = WebDriverWait(driver, 10).until(\n",
    "                            EC.presence_of_element_located((By.XPATH, description_xpath))\n",
    "                        )\n",
    "                        description = description_element.text\n",
    "                        if description:\n",
    "                            links['Descripción'] = description\n",
    "                        else:\n",
    "                            links['Descripción'] = 'No tiene descripción'\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        links['Descripción'] = 'No tiene descripción'\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    links['Descripción'] = 'No tiene descripción'\n",
    "\n",
    "            rows[row_index].update(links)\n",
    "            rows[row_index]['Processed'] = 'yes'\n",
    "            processed_rows += 1\n",
    "\n",
    "            # Escribir los cambios en el archivo CSV\n",
    "            write_to_csv(rows, fieldnames)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error al procesar la URL {company_url}: {e}\")\n",
    "            rows[row_index].update({\n",
    "                'Website': 'Error de página',\n",
    "                'LinkeIn': 'Error de página',\n",
    "                'Faceboock': 'Error de página',\n",
    "                'Twitter': 'Error de página',\n",
    "                'Descripción': 'Error de página',\n",
    "                'Processed': 'yes'\n",
    "            })\n",
    "            processed_rows += 1\n",
    "            # Escribir los cambios en el archivo CSV\n",
    "            write_to_csv(rows, fieldnames)\n",
    "            # Cerrar el navegador y reiniciar\n",
    "            driver.quit()\n",
    "            driver = start_driver()\n",
    "\n",
    "driver.quit()\n",
    "print(f\"{csv_file_path} actualizado correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando fila 603 de 24070: Ultraview AI\n",
      "No se pudo completar la tarea para Ultraview AI: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x010B8923+23283]\n",
      "\t(No symbol) [0x0107E934]\n",
      "\t(No symbol) [0x00FB0733]\n",
      "\t(No symbol) [0x00FF326F]\n",
      "\t(No symbol) [0x00FF34AB]\n",
      "\t(No symbol) [0x0102EE42]\n",
      "\t(No symbol) [0x01014464]\n",
      "\t(No symbol) [0x0102CB8D]\n",
      "\t(No symbol) [0x010141B6]\n",
      "\t(No symbol) [0x00FE8017]\n",
      "\t(No symbol) [0x00FE890D]\n",
      "\tGetHandleVerifier [0x011AA5F3+1013699]\n",
      "\tGetHandleVerifier [0x011B3E4C+1052700]\n",
      "\tGetHandleVerifier [0x011AD4B4+1025668]\n",
      "\tGetHandleVerifier [0x010DEA2B+179195]\n",
      "\t(No symbol) [0x01086833]\n",
      "\t(No symbol) [0x01083198]\n",
      "\t(No symbol) [0x01083337]\n",
      "\t(No symbol) [0x0107B4BE]\n",
      "\tBaseThreadInitThunk [0x760DFCC9+25]\n",
      "\tRtlGetAppContainerNamedObjectPath [0x770280CE+286]\n",
      "\tRtlGetAppContainerNamedObjectPath [0x7702809E+238]\n",
      "\n",
      "Procesando fila 691 de 24070: Wafi.cash\n",
      "Procesando fila 692 de 24070: MentalHappy\n",
      "Procesando fila 693 de 24070: Selflessly\n",
      "Procesando fila 694 de 24070: Glowe Connective\n",
      "Procesando fila 695 de 24070: High Tech Connect\n",
      "Procesando fila 696 de 24070: Topp & Screed USA Inc.\n",
      "Procesando fila 697 de 24070: Row64\n",
      "Procesando fila 698 de 24070: One Foot Over\n",
      "Procesando fila 699 de 24070: Keith Sconiers\n",
      "Procesando fila 700 de 24070: Randolph County NC Economic Development Corporation\n",
      "Procesando fila 701 de 24070: Broadcat\n",
      "Procesando fila 702 de 24070: Yonomi\n",
      "Procesando fila 703 de 24070: NegotiationTraining.com by TableForce\n",
      "Procesando fila 704 de 24070: OWN IT System\n",
      "Procesando fila 705 de 24070: Sidekick Solutions\n",
      "Procesando fila 706 de 24070: NimbeLink\n",
      "Procesando fila 707 de 24070: StartingPoint\n",
      "Procesando fila 708 de 24070: Learnings & Entertainments\n",
      "Procesando fila 709 de 24070: PSM Advisor (Rebranded to SAS Agency)\n",
      "Procesando fila 710 de 24070: Northcraft Analytics\n",
      "Procesando fila 711 de 24070: IMDDA\n",
      "Procesando fila 712 de 24070: Oregon Products\n",
      "Procesando fila 713 de 24070: Antelope Recovery\n",
      "Procesando fila 714 de 24070: Timothy Hogan Studio\n",
      "Procesando fila 715 de 24070: Validity Finance, LLC\n",
      "Procesando fila 716 de 24070: Orange Element\n",
      "Procesando fila 717 de 24070: Les Brown Global\n",
      "Procesando fila 718 de 24070: Collaboration In Aging\n",
      "Procesando fila 719 de 24070: VersaFeed\n",
      "Procesando fila 720 de 24070: Glanris\n",
      "Procesando fila 721 de 24070: SaveSolar Corporation\n",
      "Procesando fila 722 de 24070: Amplifinity\n",
      "Procesando fila 723 de 24070: Rebel Rabbit\n",
      "Procesando fila 724 de 24070: North County Philanthropy Council\n",
      "Procesando fila 725 de 24070: Shaping Wealth\n",
      "Procesando fila 726 de 24070: By Design Systems\n",
      "Procesando fila 727 de 24070: Syndicately\n",
      "Procesando fila 728 de 24070: Make It. MSP.\n",
      "Procesando fila 729 de 24070: Leading Elephants\n",
      "Procesando fila 730 de 24070: randrr\n",
      "Procesando fila 731 de 24070: Remote First Recruiting\n",
      "Procesando fila 732 de 24070: LLUNA\n",
      "Procesando fila 733 de 24070: CJB Applied Technologies\n",
      "Procesando fila 734 de 24070: SkyRunner, LLC\n",
      "Procesando fila 735 de 24070: Summit CNC\n",
      "Procesando fila 736 de 24070: SynergiTech\n",
      "Procesando fila 737 de 24070: Bluegrass Vascular Technologies, Inc.\n",
      "Procesando fila 738 de 24070: Wayward Kind\n",
      "Procesando fila 739 de 24070: Chilmark Research\n",
      "Procesando fila 740 de 24070: Defamation Defenders\n",
      "Procesando fila 741 de 24070: Wootric\n",
      "Procesando fila 742 de 24070: NAXO\n",
      "Procesando fila 743 de 24070: Dromo\n",
      "Procesando fila 744 de 24070: Monaghan Tooling Group\n",
      "Procesando fila 745 de 24070: Tolerisk\n",
      "Procesando fila 746 de 24070: K2 Growth Partners\n",
      "Procesando fila 747 de 24070: SWIDIA\n",
      "Procesando fila 748 de 24070: Copper & Vine Studio, Co.\n",
      "Procesando fila 749 de 24070: Clutch Recruitment\n",
      "Procesando fila 750 de 24070: Anipanion\n",
      "Procesando fila 751 de 24070: Ramp-Up Lab\n",
      "Procesando fila 752 de 24070: Hazmat Resource, Inc\n",
      "Procesando fila 753 de 24070: Medex Forensics\n",
      "Procesando fila 754 de 24070: Loup.ai\n",
      "Procesando fila 755 de 24070: Life Science Network\n",
      "Procesando fila 756 de 24070: E EQUALS WHY\n",
      "Procesando fila 757 de 24070: Orogamis\n",
      "Procesando fila 758 de 24070: Kyle Johnson Digital Marketing\n",
      "Procesando fila 759 de 24070: Huddle Inc.\n",
      "Procesando fila 760 de 24070: Where Is My Land\n",
      "Procesando fila 761 de 24070: Performance Accelerated Learning\n",
      "Procesando fila 762 de 24070: GrowthPath Partners\n",
      "Procesando fila 763 de 24070: Symphia NowForce\n",
      "Procesando fila 764 de 24070: Z+F USA\n",
      "Procesando fila 765 de 24070: Altruix in Trevose, PA\n",
      "Procesando fila 766 de 24070: Lohman Technologies\n",
      "Procesando fila 767 de 24070: Zaymo (YC W24)\n",
      "Procesando fila 768 de 24070: Innvox (Techstars '23)\n",
      "Procesando fila 769 de 24070: Upsperity\n",
      "Procesando fila 770 de 24070: MyComfortMD\n",
      "Procesando fila 771 de 24070: Panoptica: Cisco Cloud Application Security\n",
      "Procesando fila 772 de 24070: Stream 9\n",
      "Procesando fila 773 de 24070: Scope Security\n",
      "Procesando fila 774 de 24070: Aptean GenomeQuest\n",
      "Procesando fila 775 de 24070: RapidFunds\n",
      "Procesando fila 776 de 24070: Marc A. Wolfe Enterprises, LLC\n",
      "Procesando fila 777 de 24070: D-MAK Productions\n",
      "Procesando fila 778 de 24070: Expat Relocation Solutions\n",
      "Procesando fila 779 de 24070: Greelance\n",
      "Procesando fila 780 de 24070: Locus Ingredients\n",
      "Procesando fila 781 de 24070: Eye and Ear\n",
      "Procesando fila 782 de 24070: SafetyPro Resources\n",
      "Procesando fila 783 de 24070: Redhype Creative Marketing Agency\n",
      "Procesando fila 784 de 24070: CounselMore - College Counseling Software\n",
      "Procesando fila 785 de 24070: Schoolzilla by Renaissance\n",
      "Procesando fila 786 de 24070: Seed At The Table\n",
      "Procesando fila 787 de 24070: Crafted.\n",
      "Procesando fila 788 de 24070: Model Mining - Consultoría, Innovación & Tecnológica.\n",
      "Procesando fila 789 de 24070: The Tiber Group\n",
      "Procesando fila 790 de 24070: Gamma Force\n",
      "Procesando fila 791 de 24070: Endeavor Colorado\n",
      "Procesando fila 792 de 24070: Parity\n",
      "Procesando fila 793 de 24070: Stella Jets\n",
      "Procesando fila 794 de 24070: MogoARTS Marketing\n",
      "Procesando fila 795 de 24070: Crowdfunding Lawyers\n",
      "Procesando fila 796 de 24070: LA New Product Development Team\n",
      "Procesando fila 797 de 24070: PatternAI, Inc.\n",
      "Procesando fila 798 de 24070: Takeoff Monkey, LLC\n",
      "Procesando fila 799 de 24070: JMB Global Services, LLC\n",
      "Procesando fila 800 de 24070: BecomeMore Group\n",
      "Procesando fila 801 de 24070: Obsidian Manufacturing Industries, Inc.\n",
      "Procesando fila 802 de 24070: BeanStock Ventures\n",
      "Procesando fila 803 de 24070: The Lipsey Company\n",
      "Procesando fila 804 de 24070: Blackstone Discovery\n",
      "Procesando fila 805 de 24070: REACH Market Research\n",
      "Procesando fila 806 de 24070: Story2 (Acquired by Revision Learning)\n",
      "Procesando fila 807 de 24070: Palm Energy, LLC\n",
      "Procesando fila 808 de 24070: Inventory Source\n",
      "Procesando fila 809 de 24070: Pothole Bind\n",
      "Procesando fila 810 de 24070: StringCan: A B2B Growth Marketing Agency\n",
      "Procesando fila 811 de 24070: Fit3D\n",
      "Procesando fila 812 de 24070: MURO Management LLC\n",
      "Procesando fila 813 de 24070: zingfit by Xplor\n",
      "Procesando fila 814 de 24070: Concrete Sensors\n",
      "Procesando fila 815 de 24070: NextBeam\n",
      "Procesando fila 816 de 24070: Connect Veterinary Consulting\n",
      "Procesando fila 817 de 24070: Avalon Consulting, LLC\n",
      "Procesando fila 818 de 24070: Plural Studios\n",
      "Procesando fila 819 de 24070: Opel Solutions Inc\n",
      "Procesando fila 820 de 24070: IGEN\n",
      "Procesando fila 821 de 24070: Fathom Optics\n",
      "Procesando fila 822 de 24070: ModuLED - Linear Slot Lighting\n",
      "Procesando fila 823 de 24070: Dedrone Defense\n",
      "Procesando fila 824 de 24070: Opsani\n",
      "Procesando fila 825 de 24070: Clinical.ly\n",
      "Procesando fila 826 de 24070: OT Security Advisors\n",
      "Procesando fila 827 de 24070: IPTalons, Inc.\n",
      "Procesando fila 828 de 24070: SpinGo, now Events.com\n",
      "Procesando fila 829 de 24070: 406 Bovine, Inc.\n",
      "Procesando fila 830 de 24070: Work.software\n",
      "Procesando fila 831 de 24070: Talkroute\n",
      "Procesando fila 832 de 24070: Smartlink Health Solutions\n",
      "Procesando fila 833 de 24070: Retail for the People\n",
      "Procesando fila 834 de 24070: Implant Practice US, Publication & Dental Continuing Education\n",
      "Procesando fila 835 de 24070: STEM Sports®\n",
      "Procesando fila 836 de 24070: Best Ever Conference\n",
      "Procesando fila 837 de 24070: Go Studio\n",
      "Procesando fila 838 de 24070: TEDxBocaRaton\n",
      "Procesando fila 839 de 24070: Nubix\n",
      "Procesando fila 840 de 24070: MadeinAmerica.com\n",
      "Procesando fila 841 de 24070: UTA SHRM\n",
      "Procesando fila 842 de 24070: Sensytec\n",
      "Procesando fila 843 de 24070: VoiceGlance\n",
      "Procesando fila 844 de 24070: I Like Giving\n",
      "Procesando fila 845 de 24070: StartupGeek.com\n",
      "Procesando fila 846 de 24070: Armus Marine\n",
      "Procesando fila 847 de 24070: Lengea Law\n",
      "Procesando fila 848 de 24070: Form + Function\n",
      "Procesando fila 849 de 24070: Trifecta Growth Institute\n",
      "Procesando fila 850 de 24070: Ascend2\n",
      "Procesando fila 851 de 24070: Trellis Software, Inc.\n",
      "Procesando fila 852 de 24070: Brain+Trust\n",
      "Procesando fila 853 de 24070: Elite Ventures Group\n",
      "Procesando fila 854 de 24070: tefoLOGIC\n",
      "Procesando fila 855 de 24070: Luke's Circle\n",
      "Procesando fila 856 de 24070: MadHats\n",
      "Procesando fila 857 de 24070: Votary Films\n",
      "Procesando fila 858 de 24070: Cool Careers Podcast\n",
      "Procesando fila 859 de 24070: Dataman Group Direct\n",
      "Procesando fila 860 de 24070: Omaiven Health\n",
      "Procesando fila 861 de 24070: Janes Capital Partners, an Oaklins member firm\n",
      "Procesando fila 862 de 24070: OCTOPYD\n",
      "Procesando fila 863 de 24070: Abe.ai\n",
      "Procesando fila 864 de 24070: Elliott Jets\n",
      "Procesando fila 865 de 24070: Traveler's Q\n",
      "Procesando fila 866 de 24070: Cardagraph\n",
      "Procesando fila 867 de 24070: ArgoTrak\n",
      "Procesando fila 868 de 24070: Yeeld\n",
      "Procesando fila 869 de 24070: World Medical Tourism & Global Healthcare Congress\n",
      "Procesando fila 870 de 24070: NexGen Storage\n",
      "Procesando fila 871 de 24070: The Greenberg Group, Inc.\n",
      "Procesando fila 872 de 24070: iKadre\n",
      "Procesando fila 873 de 24070: Rapid Insight\n",
      "Procesando fila 874 de 24070: Chopper Spotter\n",
      "Procesando fila 875 de 24070: Ioterra\n",
      "Procesando fila 876 de 24070: LeapAnalysis\n",
      "Procesando fila 877 de 24070: Top Talent Professionals/Career Coaching NOW\n",
      "Procesando fila 878 de 24070: Sacra\n",
      "Procesando fila 879 de 24070: Grepforce\n",
      "Procesando fila 880 de 24070: 360Booth\n",
      "Procesando fila 881 de 24070: FoxyAI\n",
      "Procesando fila 882 de 24070: QueensGiant LLC\n",
      "Procesando fila 883 de 24070: The Marketing Firm, Inc.\n",
      "Procesando fila 884 de 24070: Law Office of Lawrence M. Centanni, P.C.\n",
      "Procesando fila 885 de 24070: Puzzle\n",
      "Procesando fila 886 de 24070: Blue Goat Cyber\n",
      "Procesando fila 887 de 24070: Global Market Advisors (GMA)\n",
      "Procesando fila 888 de 24070: Admit.me\n",
      "Procesando fila 889 de 24070: Black Travel Summit\n",
      "Procesando fila 890 de 24070: Student EI\n",
      "Procesando fila 891 de 24070: Fruitful Design & Strategy\n",
      "Procesando fila 892 de 24070: Foundry 45 (Acquired by Axon in April 2022)\n",
      "Procesando fila 893 de 24070: DMLift Inc.\n",
      "Procesando fila 894 de 24070: Cohero Health\n",
      "Procesando fila 895 de 24070: Enthusem by Prospect Smarter, Inc.\n",
      "Procesando fila 896 de 24070: Marketing Over Coffee Podcast\n",
      "Procesando fila 897 de 24070: Brand House Marketing\n",
      "Procesando fila 898 de 24070: ADVANCED INDUSTRIAL\n",
      "Procesando fila 899 de 24070: Adelphi Trust Company\n",
      "Procesando fila 900 de 24070: SnapRetail / SnapRx\n",
      "Procesando fila 901 de 24070: Equipment Management Group\n",
      "Procesando fila 902 de 24070: Avada Software\n",
      "Procesando fila 903 de 24070: Modus eDiscovery Inc\n",
      "Procesando fila 904 de 24070: 4Cast Agency\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Ruta absoluta del directorio de datos del usuario (debe coincidir con la usada en el primer script)\n",
    "user_data_dir = os.path.abspath(\"chrome_user_data\")\n",
    "\n",
    "# Configurar opciones de Chrome\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--start-maximized\")  # Abrir el navegador en pantalla completa\n",
    "chrome_options.add_argument(f\"user-data-dir={user_data_dir}\")  # Reusar la sesión iniciada\n",
    "\n",
    "# Descargar y configurar el controlador de Chrome automáticamente\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# Leer el archivo CSV, omitiendo líneas problemáticas\n",
    "input_file = 'Resultados/Empresas/Apollo_Acounts_1-10 copy.csv'\n",
    "df = pd.read_csv(input_file, on_bad_lines='skip')\n",
    "\n",
    "# Verificar si el archivo final existe, si no, crear un DataFrame vacío\n",
    "output_file = 'Prospects_with_all_data.csv'\n",
    "if os.path.exists(output_file):\n",
    "    final_df = pd.read_csv(output_file)\n",
    "else:\n",
    "    final_df = pd.DataFrame()\n",
    "\n",
    "def extract_table_data(table_xpath, pagination_xpath):\n",
    "    table_data = []\n",
    "    while True:\n",
    "        # Buscar la tabla con el XPath especificado\n",
    "        table = WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.XPATH, table_xpath))\n",
    "        )\n",
    "\n",
    "        # Extraer los datos de la tabla\n",
    "        time.sleep(2)\n",
    "        table_rows = table.find_elements(By.TAG_NAME, 'tr')\n",
    "\n",
    "        if not table_rows:\n",
    "            break\n",
    "\n",
    "        headers = [header.text for header in table_rows[0].find_elements(By.TAG_NAME, 'th')]\n",
    "        if not headers:  # Si no hay elementos <th>, usar <td> de la primera fila\n",
    "            headers = [header.text for header in table_rows[0].find_elements(By.TAG_NAME, 'td')]\n",
    "\n",
    "        try:\n",
    "            quick_actions_index = headers.index('Quick Actions')\n",
    "        except ValueError:\n",
    "            quick_actions_index = -1\n",
    "\n",
    "        if quick_actions_index != -1:\n",
    "            headers.pop(quick_actions_index)\n",
    "\n",
    "        for row in table_rows[1:]:  # Omitir la primera fila de encabezados\n",
    "            cells = row.find_elements(By.TAG_NAME, 'td')\n",
    "            row_data = [cell.text for i, cell in enumerate(cells) if i != quick_actions_index]\n",
    "\n",
    "            if 'Name' in headers:\n",
    "                name_cell = cells[headers.index('Name')]\n",
    "                name_link_element = name_cell.find_element(By.TAG_NAME, 'a')\n",
    "                apollo_profile_url = name_link_element.get_attribute('href')\n",
    "                row_data.append(apollo_profile_url)\n",
    "            else:\n",
    "                row_data.append(None)\n",
    "\n",
    "            table_data.append(row_data)\n",
    "\n",
    "        headers.append('Apollo Profile URL')\n",
    "        table_df = pd.DataFrame(table_data, columns=headers)\n",
    "\n",
    "        if not table_df.empty:\n",
    "            table_df['Company'] = company_name\n",
    "            table_df['Website'] = website\n",
    "\n",
    "            global final_df\n",
    "            if not final_df.empty:\n",
    "                final_df = pd.concat([final_df, table_df], ignore_index=True)\n",
    "            else:\n",
    "                final_df = table_df\n",
    "\n",
    "        # Buscar el botón \"Siguiente\"\n",
    "        try:\n",
    "            next_button = WebDriverWait(driver, 5).until(\n",
    "                EC.presence_of_element_located((By.XPATH, pagination_xpath))\n",
    "            )\n",
    "            \n",
    "            # Verificar si el botón \"Siguiente\" está habilitado\n",
    "            if 'disabled' in next_button.get_attribute('class') or 'disabled' in next_button.get_attribute('aria-disabled'):\n",
    "                break  # Si el botón está deshabilitado, salir del bucle\n",
    "            \n",
    "            next_button.click()\n",
    "            time.sleep(2)\n",
    "        except Exception:\n",
    "            break  # Si no se encuentra el botón \"Siguiente\", salir del bucle\n",
    "\n",
    "def process_company_row(row):\n",
    "    global company_name, website\n",
    "    company_url = row['Company URL']\n",
    "    company_name = row['Company']\n",
    "    website = row['Website']\n",
    "\n",
    "    try:\n",
    "        driver.get(company_url)\n",
    "\n",
    "        try:\n",
    "            # Intentar buscar el enlace 'Employees'\n",
    "            employees_link = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.XPATH, '/html/body/div[2]/div/div[2]/div[2]/div/div[2]/div/div/div[2]/div[2]/div/div/div/div[2]/div/div[1]/div/a[5]'))\n",
    "            )\n",
    "            employees_link.click()\n",
    "            extract_table_data('/html/body/div[2]/div/div[2]/div[2]/div/div[2]/div/div/div[2]/div[2]/div/div/div/div[2]/div/div[2]/div/div/div/div/div/div[4]/div/div/div/div/div[2]/div/table',\n",
    "                               '/html/body/div[2]/div/div[2]/div[2]/div/div[2]/div/div/div[2]/div[2]/div/div/div/div[2]/div/div[2]/div/div/div/div/div/div[4]/div/div/div/div/div[3]/div/div[2]/button[2]')\n",
    "\n",
    "        except Exception:\n",
    "            # Si no se encuentra 'Employees', buscar 'People'\n",
    "            people_link = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.XPATH, '/html/body/div[2]/div/div[2]/div[2]/div/div[2]/div/div/div[2]/div[2]/div/div/div/div[1]/div[2]/div/div/div[1]/div/a[3]'))\n",
    "            )\n",
    "            people_link.click()\n",
    "            extract_table_data('/html/body/div[2]/div/div[2]/div[2]/div/div[2]/div/div/div[2]/div[2]/div/div/div/div[1]/div[2]/div/div/div[2]/div/div/div/div/div/div[3]/div/div/div/div/div[2]/div/table',\n",
    "                               '/html/body/div[2]/div/div[2]/div[2]/div/div[2]/div/div/div[2]/div[2]/div/div/div/div[1]/div[2]/div/div/div[2]/div/div/div/div/div/div[3]/div/div/div/div/div[3]/div/div[2]/button[2]')\n",
    "        \n",
    "        final_df.to_csv(output_file, index=False)\n",
    "        # print(f\"Datos de '{company_name}' añadidos a '{output_file}'.\")\n",
    "\n",
    "        # Marcar fila como procesada en el archivo original\n",
    "        df.at[row.name, 'Processed'] = 'Yes'\n",
    "        df.to_csv(input_file, index=False)\n",
    "        # print(f\"Archivo original actualizado: '{company_name}' marcado como procesado.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"No se pudo completar la tarea para {company_name}: {str(e)}\")\n",
    "\n",
    "# Iterar sobre cada fila del DataFrame, si no está procesada\n",
    "for index, row in df.iterrows():\n",
    "    if pd.isna(row.get('Processed')) or row['Processed'] != 'Yes':\n",
    "        print(f\"Procesando fila {index + 1} de {len(df)}: {row['Company']}\")  # Mensaje para imprimir la fila actual\n",
    "        process_company_row(row)\n",
    "\n",
    "print(\"Proceso terminado\")\n",
    "\n",
    "# Cerrar el navegador\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Ruta absoluta del directorio de datos del usuario (debe coincidir con la usada en el primer script)\n",
    "user_data_dir = os.path.abspath(\"chrome_user_data\")\n",
    "\n",
    "# Configurar opciones de Chrome\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--start-maximized\")  # Abrir el navegador en pantalla completa\n",
    "chrome_options.add_argument(f\"user-data-dir={user_data_dir}\")  # Reusar la sesión iniciada\n",
    "\n",
    "# Descargar y configurar el controlador de Chrome automáticamente\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# Leer el archivo CSV\n",
    "input_file = 'Prospects_with_all_data.csv'  # Nombre del archivo generado anteriormente\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Verificar si los archivos finales existen, si no, crear DataFrames vacíos\n",
    "output_file_linkedin = 'Prospects_with_linkedin_profiles.csv'\n",
    "output_file_no_linkedin = 'Prospects_without_linkedin_profiles.csv'\n",
    "\n",
    "if os.path.exists(output_file_linkedin):\n",
    "    final_df_linkedin = pd.read_csv(output_file_linkedin)\n",
    "else:\n",
    "    final_df_linkedin = pd.DataFrame()\n",
    "\n",
    "if os.path.exists(output_file_no_linkedin):\n",
    "    final_df_no_linkedin = pd.read_csv(output_file_no_linkedin)\n",
    "else:\n",
    "    final_df_no_linkedin = pd.DataFrame()\n",
    "\n",
    "# Iterar sobre cada fila del DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    if pd.isna(row.get('Processed')) or row['Processed'] != 'Yes':\n",
    "        print(f\"Procesando fila {index + 1} de {len(df)}\")\n",
    "        \n",
    "        apollo_profile_url = row['Apollo Profile URL']\n",
    "        company_name = row['Company']\n",
    "        website = row['Website']\n",
    "        \n",
    "        try:\n",
    "            driver.get(apollo_profile_url)\n",
    "\n",
    "            # Buscar el enlace de LinkedIn con el XPath especificado\n",
    "            try:\n",
    "                linkedin_element = WebDriverWait(driver, 20).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, '/html/body/div[2]/div/div[2]/div[2]/div/div[2]/div/div/div[2]/div[2]/div/div/div/div[1]/div[1]/div[1]/div/div/div/div/div[1]/div/div[1]/div/div[1]/div[1]/a'))\n",
    "                )\n",
    "                \n",
    "                time.sleep(2)\n",
    "\n",
    "                linkedin_url = linkedin_element.get_attribute('href')\n",
    "\n",
    "                # Verificar que el enlace empiece con \"https://www.linkedin.com/\" o \"http://www.linkedin.com/\"\n",
    "                if linkedin_url.startswith('https://www.linkedin.com/') or linkedin_url.startswith('http://www.linkedin.com/'):\n",
    "                    row['LinkedIn Profile'] = linkedin_url\n",
    "                    final_df_linkedin = pd.concat([final_df_linkedin, pd.DataFrame([row])], ignore_index=True)\n",
    "                    final_df_linkedin.to_csv(output_file_linkedin, index=False)\n",
    "                    print(f\"LinkedIn para {company_name} añadido a '{output_file_linkedin}'.\")\n",
    "                else:\n",
    "                    print(f\"El enlace de LinkedIn para {company_name} no comienza con 'https://www.linkedin.com/' o 'http://www.linkedin.com/'.\")\n",
    "                    final_df_no_linkedin = pd.concat([final_df_no_linkedin, pd.DataFrame([row])], ignore_index=True)\n",
    "                    final_df_no_linkedin.to_csv(output_file_no_linkedin, index=False)\n",
    "                    print(f\"Contacto de {company_name} añadido a '{output_file_no_linkedin}' (no se encontró LinkedIn).\")\n",
    "\n",
    "            except Exception:\n",
    "                print(f\"No se pudo encontrar el enlace de LinkedIn para {company_name}\")\n",
    "                final_df_no_linkedin = pd.concat([final_df_no_linkedin, pd.DataFrame([row])], ignore_index=True)\n",
    "                final_df_no_linkedin.to_csv(output_file_no_linkedin, index=False)\n",
    "                print(f\"Contacto de {company_name} añadido a '{output_file_no_linkedin}' (no se encontró LinkedIn).\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error al acceder a la URL {apollo_profile_url}\")\n",
    "        \n",
    "        # Marcar la fila como procesada\n",
    "        df.at[index, 'Processed'] = 'Yes'\n",
    "        df.to_csv(input_file, index=False)\n",
    "        print(f\"Fila {index + 1} de {len(df)} marcada como procesada en '{input_file}'.\")\n",
    "\n",
    "print(\"Proceso terminado\")\n",
    "\n",
    "# Cerrar el navegador\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

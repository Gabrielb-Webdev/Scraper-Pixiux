{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Ruta absoluta del directorio de datos del usuario\n",
    "user_data_dir = os.path.abspath(\"chrome_user_data\")\n",
    "\n",
    "# Crear el directorio si no existe\n",
    "if not os.path.exists(user_data_dir):\n",
    "    os.makedirs(user_data_dir)\n",
    "\n",
    "# Configurar opciones de Chrome\n",
    "chrome_options = Options()\n",
    "# chrome_options.add_argument(\"--headless\")  # Ejecutar en modo headless\n",
    "chrome_options.add_argument(\"--start-maximized\")  # Abrir el navegador en pantalla completa\n",
    "# Establecer el perfil de usuario\n",
    "chrome_options.add_argument(f\"user-data-dir={user_data_dir}\")\n",
    "\n",
    "# Descargar y configurar el controlador de Chrome automáticamente\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# Abrir el navegador y navegar a Apollo.io\n",
    "driver.get(\"https://app.apollo.io/#/login\")\n",
    "\n",
    "# Esperar unos segundos para ver el navegador abierto antes de empezar a interactuar\n",
    "time.sleep(5)\n",
    "\n",
    "# Intentar encontrar el campo de correo electrónico por su XPath y rellenarlo\n",
    "email_xpath = '/html/body/div[2]/div/div[2]/div/div[1]/div/div[2]/div/div[2]/div/form/div[2]/div/div/input'\n",
    "try:\n",
    "    email_input = WebDriverWait(driver, 10).until(\n",
    "        EC.visibility_of_element_located((By.XPATH, email_xpath))\n",
    "    )\n",
    "    email_input.send_keys(\"Gbustosgarcia01@gmail.com\")\n",
    "    print(\"El campo de correo electrónico fue rellenado.\")\n",
    "except Exception as e:\n",
    "    print(f\"El campo de correo electrónico no fue encontrado: {e}\")\n",
    "\n",
    "# Intentar encontrar el campo de contraseña por su XPath y rellenarlo\n",
    "password_xpath = '/html/body/div[2]/div/div[2]/div/div[1]/div/div[2]/div/div[2]/div/form/div[3]/div/div[1]/div/input'\n",
    "try:\n",
    "    password_input = WebDriverWait(driver, 10).until(\n",
    "        EC.visibility_of_element_located((By.XPATH, password_xpath))\n",
    "    )\n",
    "    password_input.send_keys(\"LG030920..lg.\")\n",
    "    print(\"El campo de contraseña fue rellenado.\")\n",
    "except Exception as e:\n",
    "    print(f\"El campo de contraseña no fue encontrado: {e}\")\n",
    "\n",
    "# Intentar encontrar el botón de Log In por su XPath y hacer clic en él\n",
    "login_button_xpath = '/html/body/div[2]/div/div[2]/div/div[1]/div/div[2]/div/div[2]/div/form/div[4]/button'\n",
    "try:\n",
    "    login_button = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, login_button_xpath))\n",
    "    )\n",
    "    login_button.click()\n",
    "    print(\"El botón de Log In fue clickeado.\")\n",
    "except Exception as e:\n",
    "    print(f\"El botón de Log In no fue encontrado o no fue clickeable: {e}\")\n",
    "\n",
    "# Esperar unos segundos para asegurar que el inicio de sesión se complete\n",
    "time.sleep(10)\n",
    "\n",
    "# Cerrar el navegador\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import csv\n",
    "import time\n",
    "\n",
    "# Configurar opciones de Chrome\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Ejecutar en modo headless\n",
    "chrome_options.add_argument(\"--start-maximized\")  # Abrir el navegador en pantalla completa\n",
    "user_data_dir = \"chrome_user_data\"\n",
    "chrome_options.add_argument(f\"user-data-dir={user_data_dir}\")\n",
    "\n",
    "# Descargar y configurar el controlador de Chrome automáticamente\n",
    "def start_driver():\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    return webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "driver = start_driver()\n",
    "\n",
    "csv_file_path = 'Resultados/Empresas/Apollo_Acounts_1-10.csv'\n",
    "rows = []\n",
    "company_urls = {}  # Diccionario para mapear URLs a sus índices de fila\n",
    "\n",
    "# Verificar y añadir columnas si no existen\n",
    "with open(csv_file_path, mode='r', newline='', encoding='utf-8') as file:\n",
    "    csv_reader = csv.DictReader(file)\n",
    "    existing_fieldnames = csv_reader.fieldnames\n",
    "    required_columns = ['Website', 'LinkeIn', 'Faceboock', 'Twitter', 'Descripción', 'Processed']\n",
    "    \n",
    "    if not all(column in existing_fieldnames for column in required_columns):\n",
    "        fieldnames = existing_fieldnames + [column for column in required_columns if column not in existing_fieldnames]\n",
    "    else:\n",
    "        fieldnames = existing_fieldnames\n",
    "\n",
    "    for index, row in enumerate(csv_reader):\n",
    "        rows.append(row)\n",
    "        company_urls[row.get('Company URL')] = index  # Guardar el índice de fila por URL\n",
    "\n",
    "num_rows_to_process = 10000  # Cambia este valor según sea necesario\n",
    "processed_rows = 0\n",
    "\n",
    "def write_to_csv(rows, fieldnames):\n",
    "    with open(csv_file_path, mode='w', newline='', encoding='utf-8') as updated_file:\n",
    "        csv_writer = csv.DictWriter(updated_file, fieldnames=fieldnames)\n",
    "        csv_writer.writeheader()\n",
    "        csv_writer.writerows(rows)\n",
    "\n",
    "for row_index, row in enumerate(rows):\n",
    "    if processed_rows >= num_rows_to_process:\n",
    "        break\n",
    "\n",
    "    if row.get('Processed') == 'yes':\n",
    "        print(f\"Fila {row_index + 1} ya está completa. Pasando a la siguiente fila.\")\n",
    "        continue\n",
    "\n",
    "    if any([not row.get(col, '').strip() for col in required_columns if col != 'Processed']):\n",
    "        company_name = row.get('Company', '')\n",
    "        company_url = row.get('Company URL', '')\n",
    "\n",
    "        print(f\"Procesando fila {row_index + 1} - Empresa: {company_name}\")\n",
    "\n",
    "        try:\n",
    "            driver.get(company_url)\n",
    "            time.sleep(2)\n",
    "\n",
    "            div_xpath = '/html/body/div[2]/div/div[2]/div[2]/div/div[2]/div/div/div[2]/div[2]/div/div/div/div[1]/div[1]/div[1]/div/div/div/div/div[1]/div[2]'\n",
    "            links = {\n",
    "                'Website': row.get('Website', 'No tiene Website'),\n",
    "                'LinkeIn': row.get('LinkeIn', 'No tiene LinkeIn'),\n",
    "                'Faceboock': row.get('Faceboock', 'No tiene Faceboock'),\n",
    "                'Twitter': row.get('Twitter', 'No tiene Twitter'),\n",
    "                'Descripción': row.get('Descripción', 'No tiene descripción'),\n",
    "            }\n",
    "\n",
    "            if any([not row.get(col, '').strip() for col in required_columns if col != 'Processed']):\n",
    "                try:\n",
    "                    div_element = WebDriverWait(driver, 10).until(\n",
    "                        EC.presence_of_element_located((By.XPATH, div_xpath))\n",
    "                    )\n",
    "                    link_elements = div_element.find_elements(By.TAG_NAME, 'a')\n",
    "                    \n",
    "                    for link in link_elements:\n",
    "                        href = link.get_attribute('href')\n",
    "                        if href:\n",
    "                            if 'linkedin.com' in href:\n",
    "                                links['LinkeIn'] = href\n",
    "                            elif 'facebook.com' in href:\n",
    "                                links['Faceboock'] = href\n",
    "                            elif 'twitter.com' in href or 'x.com' in href:\n",
    "                                links['Twitter'] = href\n",
    "                            else:\n",
    "                                if links['Website'] == 'No tiene Website':\n",
    "                                    links['Website'] = href\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"No se pudo encontrar el div con enlaces: {e}\")\n",
    "\n",
    "                show_more_xpath = '/html/body/div[2]/div/div[2]/div[2]/div/div[2]/div/div/div[2]/div[2]/div/div/div/div[1]/div[1]/div[2]/div/div/div/div/div/div[1]/div/div/div/span/a'\n",
    "                try:\n",
    "                    show_more_button = WebDriverWait(driver, 10).until(\n",
    "                        EC.element_to_be_clickable((By.XPATH, show_more_xpath))\n",
    "                    )\n",
    "                    show_more_button.click()\n",
    "                    \n",
    "                    time.sleep(2)\n",
    "                    \n",
    "                    description_xpath = '/html/body/div[2]/div/div[2]/div[2]/div/div[2]/div/div/div[2]/div[2]/div/div/div/div[1]/div[1]/div[2]/div/div/div/div/div/div[1]/div/div/div/span/span'\n",
    "                    try:\n",
    "                        description_element = WebDriverWait(driver, 10).until(\n",
    "                            EC.presence_of_element_located((By.XPATH, description_xpath))\n",
    "                        )\n",
    "                        description = description_element.text\n",
    "                        if description:\n",
    "                            links['Descripción'] = description\n",
    "                        else:\n",
    "                            links['Descripción'] = 'No tiene descripción'\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        links['Descripción'] = 'No tiene descripción'\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    links['Descripción'] = 'No tiene descripción'\n",
    "\n",
    "            rows[row_index].update(links)\n",
    "            rows[row_index]['Processed'] = 'yes'\n",
    "            processed_rows += 1\n",
    "\n",
    "            # Escribir los cambios en el archivo CSV\n",
    "            write_to_csv(rows, fieldnames)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error al procesar la URL {company_url}: {e}\")\n",
    "            rows[row_index].update({\n",
    "                'Website': 'Error de página',\n",
    "                'LinkeIn': 'Error de página',\n",
    "                'Faceboock': 'Error de página',\n",
    "                'Twitter': 'Error de página',\n",
    "                'Descripción': 'Error de página',\n",
    "                'Processed': 'yes'\n",
    "            })\n",
    "            processed_rows += 1\n",
    "            # Escribir los cambios en el archivo CSV\n",
    "            write_to_csv(rows, fieldnames)\n",
    "            # Cerrar el navegador y reiniciar\n",
    "            driver.quit()\n",
    "            driver = start_driver()\n",
    "\n",
    "driver.quit()\n",
    "print(f\"{csv_file_path} actualizado correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Ruta absoluta del directorio de datos del usuario (debe coincidir con la usada en el primer script)\n",
    "user_data_dir = os.path.abspath(\"chrome_user_data\")\n",
    "\n",
    "# Configurar opciones de Chrome\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--start-maximized\")  # Abrir el navegador en pantalla completa\n",
    "chrome_options.add_argument(f\"user-data-dir={user_data_dir}\")  # Reusar la sesión iniciada\n",
    "\n",
    "# Descargar y configurar el controlador de Chrome automáticamente\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# Leer el archivo CSV, omitiendo líneas problemáticas\n",
    "input_file = 'Resultados/Empresas/Apollo_Acounts_1-10 copy.csv'\n",
    "df = pd.read_csv(input_file, on_bad_lines='skip')\n",
    "\n",
    "# Verificar si el archivo final existe, si no, crear un DataFrame vacío\n",
    "output_file = 'Prospects_with_all_data.csv'\n",
    "if os.path.exists(output_file):\n",
    "    final_df = pd.read_csv(output_file)\n",
    "else:\n",
    "    final_df = pd.DataFrame()\n",
    "\n",
    "def extract_table_data(table_xpath, pagination_xpath):\n",
    "    table_data = []\n",
    "    while True:\n",
    "        # Buscar la tabla con el XPath especificado\n",
    "        table = WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.XPATH, table_xpath))\n",
    "        )\n",
    "\n",
    "        # Extraer los datos de la tabla\n",
    "        time.sleep(2)\n",
    "        table_rows = table.find_elements(By.TAG_NAME, 'tr')\n",
    "\n",
    "        if not table_rows:\n",
    "            break\n",
    "\n",
    "        headers = [header.text for header in table_rows[0].find_elements(By.TAG_NAME, 'th')]\n",
    "        if not headers:  # Si no hay elementos <th>, usar <td> de la primera fila\n",
    "            headers = [header.text for header in table_rows[0].find_elements(By.TAG_NAME, 'td')]\n",
    "\n",
    "        try:\n",
    "            quick_actions_index = headers.index('Quick Actions')\n",
    "        except ValueError:\n",
    "            quick_actions_index = -1\n",
    "\n",
    "        if quick_actions_index != -1:\n",
    "            headers.pop(quick_actions_index)\n",
    "\n",
    "        for row in table_rows[1:]:  # Omitir la primera fila de encabezados\n",
    "            cells = row.find_elements(By.TAG_NAME, 'td')\n",
    "            row_data = [cell.text for i, cell in enumerate(cells) if i != quick_actions_index]\n",
    "\n",
    "            if 'Name' in headers:\n",
    "                name_cell = cells[headers.index('Name')]\n",
    "                name_link_element = name_cell.find_element(By.TAG_NAME, 'a')\n",
    "                apollo_profile_url = name_link_element.get_attribute('href')\n",
    "                row_data.append(apollo_profile_url)\n",
    "            else:\n",
    "                row_data.append(None)\n",
    "\n",
    "            table_data.append(row_data)\n",
    "\n",
    "        headers.append('Apollo Profile URL')\n",
    "        table_df = pd.DataFrame(table_data, columns=headers)\n",
    "\n",
    "        if not table_df.empty:\n",
    "            table_df['Company'] = company_name\n",
    "            table_df['Website'] = website\n",
    "\n",
    "            global final_df\n",
    "            if not final_df.empty:\n",
    "                final_df = pd.concat([final_df, table_df], ignore_index=True)\n",
    "            else:\n",
    "                final_df = table_df\n",
    "\n",
    "        # Buscar el botón \"Siguiente\"\n",
    "        try:\n",
    "            next_button = WebDriverWait(driver, 5).until(\n",
    "                EC.presence_of_element_located((By.XPATH, pagination_xpath))\n",
    "            )\n",
    "            \n",
    "            # Verificar si el botón \"Siguiente\" está habilitado\n",
    "            if 'disabled' in next_button.get_attribute('class') or 'disabled' in next_button.get_attribute('aria-disabled'):\n",
    "                break  # Si el botón está deshabilitado, salir del bucle\n",
    "            \n",
    "            next_button.click()\n",
    "            time.sleep(2)\n",
    "        except Exception:\n",
    "            break  # Si no se encuentra el botón \"Siguiente\", salir del bucle\n",
    "\n",
    "def process_company_row(row):\n",
    "    global company_name, website\n",
    "    company_url = row['Company URL']\n",
    "    company_name = row['Company']\n",
    "    website = row['Website']\n",
    "\n",
    "    try:\n",
    "        driver.get(company_url)\n",
    "\n",
    "        try:\n",
    "            # Intentar buscar el enlace 'Employees'\n",
    "            employees_link = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.XPATH, '/html/body/div[2]/div/div[2]/div[2]/div/div[2]/div/div/div[2]/div[2]/div/div/div/div[2]/div/div[1]/div/a[5]'))\n",
    "            )\n",
    "            employees_link.click()\n",
    "            extract_table_data('/html/body/div[2]/div/div[2]/div[2]/div/div[2]/div/div/div[2]/div[2]/div/div/div/div[2]/div/div[2]/div/div/div/div/div/div[4]/div/div/div/div/div[2]/div/table',\n",
    "                               '/html/body/div[2]/div/div[2]/div[2]/div/div[2]/div/div/div[2]/div[2]/div/div/div/div[2]/div/div[2]/div/div/div/div/div/div[4]/div/div/div/div/div[3]/div/div[2]/button[2]')\n",
    "\n",
    "        except Exception:\n",
    "            # Si no se encuentra 'Employees', buscar 'People'\n",
    "            people_link = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.XPATH, '/html/body/div[2]/div/div[2]/div[2]/div/div[2]/div/div/div[2]/div[2]/div/div/div/div[1]/div[2]/div/div/div[1]/div/a[3]'))\n",
    "            )\n",
    "            people_link.click()\n",
    "            extract_table_data('/html/body/div[2]/div/div[2]/div[2]/div/div[2]/div/div/div[2]/div[2]/div/div/div/div[1]/div[2]/div/div/div[2]/div/div/div/div/div/div[3]/div/div/div/div/div[2]/div/table',\n",
    "                               '/html/body/div[2]/div/div[2]/div[2]/div/div[2]/div/div/div[2]/div[2]/div/div/div/div[1]/div[2]/div/div/div[2]/div/div/div/div/div/div[3]/div/div/div/div/div[3]/div/div[2]/button[2]')\n",
    "        \n",
    "        final_df.to_csv(output_file, index=False)\n",
    "        # print(f\"Datos de '{company_name}' añadidos a '{output_file}'.\")\n",
    "\n",
    "        # Marcar fila como procesada en el archivo original\n",
    "        df.at[row.name, 'Processed'] = 'Yes'\n",
    "        df.to_csv(input_file, index=False)\n",
    "        # print(f\"Archivo original actualizado: '{company_name}' marcado como procesado.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"No se pudo completar la tarea para {company_name}: {str(e)}\")\n",
    "\n",
    "# Iterar sobre cada fila del DataFrame, si no está procesada\n",
    "for index, row in df.iterrows():\n",
    "    if pd.isna(row.get('Processed')) or row['Processed'] != 'Yes':\n",
    "        print(f\"Procesando fila {index + 1} de {len(df)}: {row['Company']}\")  # Mensaje para imprimir la fila actual\n",
    "        process_company_row(row)\n",
    "\n",
    "print(\"Proceso terminado\")\n",
    "\n",
    "# Cerrar el navegador\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Ruta absoluta del directorio de datos del usuario (debe coincidir con la usada en el primer script)\n",
    "user_data_dir = os.path.abspath(\"chrome_user_data\")\n",
    "\n",
    "# Configurar opciones de Chrome\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--start-maximized\")  # Abrir el navegador en pantalla completa\n",
    "chrome_options.add_argument(f\"user-data-dir={user_data_dir}\")  # Reusar la sesión iniciada\n",
    "\n",
    "# Descargar y configurar el controlador de Chrome automáticamente\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# Leer el archivo CSV\n",
    "input_file = 'Prospects_with_all_data.csv'  # Nombre del archivo generado anteriormente\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Verificar si los archivos finales existen, si no, crear DataFrames vacíos\n",
    "output_file_linkedin = 'Prospects_with_linkedin_profiles.csv'\n",
    "output_file_no_linkedin = 'Prospects_without_linkedin_profiles.csv'\n",
    "\n",
    "if os.path.exists(output_file_linkedin):\n",
    "    final_df_linkedin = pd.read_csv(output_file_linkedin)\n",
    "else:\n",
    "    final_df_linkedin = pd.DataFrame()\n",
    "\n",
    "if os.path.exists(output_file_no_linkedin):\n",
    "    final_df_no_linkedin = pd.read_csv(output_file_no_linkedin)\n",
    "else:\n",
    "    final_df_no_linkedin = pd.DataFrame()\n",
    "\n",
    "# Iterar sobre cada fila del DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    if pd.isna(row.get('Processed')) or row['Processed'] != 'Yes':\n",
    "        print(f\"Procesando fila {index + 1} de {len(df)}\")\n",
    "        \n",
    "        apollo_profile_url = row['Apollo Profile URL']\n",
    "        company_name = row['Company']\n",
    "        website = row['Website']\n",
    "        \n",
    "        try:\n",
    "            driver.get(apollo_profile_url)\n",
    "\n",
    "            # Buscar el enlace de LinkedIn con el XPath especificado\n",
    "            try:\n",
    "                linkedin_element = WebDriverWait(driver, 20).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, '/html/body/div[2]/div/div[2]/div[2]/div/div[2]/div/div/div[2]/div[2]/div/div/div/div[1]/div[1]/div[1]/div/div/div/div/div[1]/div/div[1]/div/div[1]/div[1]/a'))\n",
    "                )\n",
    "                \n",
    "                time.sleep(2)\n",
    "\n",
    "                linkedin_url = linkedin_element.get_attribute('href')\n",
    "\n",
    "                # Verificar que el enlace empiece con \"https://www.linkedin.com/\" o \"http://www.linkedin.com/\"\n",
    "                if linkedin_url.startswith('https://www.linkedin.com/') or linkedin_url.startswith('http://www.linkedin.com/'):\n",
    "                    row['LinkedIn Profile'] = linkedin_url\n",
    "                    final_df_linkedin = pd.concat([final_df_linkedin, pd.DataFrame([row])], ignore_index=True)\n",
    "                    final_df_linkedin.to_csv(output_file_linkedin, index=False)\n",
    "                    print(f\"LinkedIn para {company_name} añadido a '{output_file_linkedin}'.\")\n",
    "                else:\n",
    "                    print(f\"El enlace de LinkedIn para {company_name} no comienza con 'https://www.linkedin.com/' o 'http://www.linkedin.com/'.\")\n",
    "                    final_df_no_linkedin = pd.concat([final_df_no_linkedin, pd.DataFrame([row])], ignore_index=True)\n",
    "                    final_df_no_linkedin.to_csv(output_file_no_linkedin, index=False)\n",
    "                    print(f\"Contacto de {company_name} añadido a '{output_file_no_linkedin}' (no se encontró LinkedIn).\")\n",
    "\n",
    "            except Exception:\n",
    "                print(f\"No se pudo encontrar el enlace de LinkedIn para {company_name}\")\n",
    "                final_df_no_linkedin = pd.concat([final_df_no_linkedin, pd.DataFrame([row])], ignore_index=True)\n",
    "                final_df_no_linkedin.to_csv(output_file_no_linkedin, index=False)\n",
    "                print(f\"Contacto de {company_name} añadido a '{output_file_no_linkedin}' (no se encontró LinkedIn).\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error al acceder a la URL {apollo_profile_url}\")\n",
    "        \n",
    "        # Marcar la fila como procesada\n",
    "        df.at[index, 'Processed'] = 'Yes'\n",
    "        df.to_csv(input_file, index=False)\n",
    "        print(f\"Fila {index + 1} de {len(df)} marcada como procesada en '{input_file}'.\")\n",
    "\n",
    "print(\"Proceso terminado\")\n",
    "\n",
    "# Cerrar el navegador\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
